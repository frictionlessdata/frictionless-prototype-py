# frictionless-py

[![Travis](https://img.shields.io/travis/frictionlessdata/frictionless-py/master.svg)](https://travis-ci.org/frictionlessdata/frictionless-py)
[![Coveralls](http://img.shields.io/coveralls/frictionlessdata/frictionless-py.svg?branch=master)](https://coveralls.io/r/frictionlessdata/frictionless-py?branch=master)
[![PyPi](https://img.shields.io/pypi/v/frictionless.svg)](https://pypi.python.org/pypi/frictionless)
[![Github](https://img.shields.io/badge/github-master-brightgreen)](https://github.com/frictionlessdata/frictionless-py)
[![Discord](https://img.shields.io/gitter/room/frictionlessdata/chat.svg)](https://discord.com/channels/695635777199145130/695635777199145133)

Frictionless is a framework to describe, extract, validate, and transform tabular data. It supports a great deal of data sources and formats, as well as provides popular platforms integrations. The framework is powered by the lightweight yet comprehensive [Frictionless Data Specifications](https://specs.frictionlessdata.io/).

## Features

- **Describe your data**: You can infer, edit and save metadata of your data tables. It's a first step for ensuring data quality and usability. Frictionless metadata includes general information about your data like textual description, as well as, field types and other tabular data details.
- **Extract your data**: You can read your data using a unified tabular interface. Data quality and consistency are guaranteed by a schema. Frictionless supports various file protocols like HTTP, FTP, and S3 and data formats like CSV, XLS, JSON, SQL, and others.
- **Validate your data**: You can validate data tables, resources, and datasets. Frictionless generates a unified validation report, as well as supports a lot of options to customize the validation process.
- **Transform your data**: You can clean, reshape, and transfer your data tables and datasets. Frictionless provides a pipeline capability and a lower-level interface to work with the data.

---

- powerful command-line interface
- low memory consumption for data of any size
- reasonable performance on big data
- support for compressed files
- custom checks and formats
- fully pluggable architecture
- the included API server
- more than 1000+ tests

## Documentation

- [Getting Started](docs/build/getting-started/README.md)
- [Introductory Guide](docs/build/introductory-guide/README.md)
- [Describing Data](docs/build/describing-data/README.md)
- [Extracting Data](docs/build/extracting-data/README.md)
- [Validating Data](docs/build/validating-data/README.md)
- [Transforming Data](docs/build/transforming-data/README.md)
- [Schemes Reference](docs/build/schemes-reference/README.md)
- [Formats Reference](docs/build/formats-reference/README.md)
- [Errors Reference](docs/build/errors-reference/README.md)
- [API Reference](docs/build/api-reference/README.md)
- [Extension Guide](docs/build/extension-guide/README.md)
- [Contribution Guide](docs/build/contribution-guide/README.md)
- [Contributors](docs/build/contributors/README.md)
- [Changelog](docs/build/changelog/README.md)
